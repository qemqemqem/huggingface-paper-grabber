Papersarxiv:2505.04388The Aloe Family Recipe for Open and Specialized Healthcare LLMsPublished on May 7·Submitted bydariogon May 21Upvote20+12Authors:Dario Garcia-Gasulla,Jordi Bayarri-Planas,Ashwin Kumar Gururajan,Enrique Lopez-Cuena,Adrian Tormos,Daniel Hinjos,Pablo Bernabeu-Perez,Anna Arias-Duart,Pablo Agustin Martin-Torres,Marta Gonzalez-Mallo,Sergio Alvarez-Napagao,Eduard Ayguadé-Parra,Ulises CortésPurpose: With advancements inLarge Language Models(LLMs) for healthcare,
the need arises for competitive open-source models to protect the public
interest. This work contributes to the field of open medicalLLMsby optimizing
key stages of data preprocessing and training, while showing how to improve
model safety (throughDPO) and efficacy (throughRAG). The evaluation
methodology used, which includes four different types of tests, defines a new
standard for the field. The resultant models, shown to be competitive with the
best private alternatives, are released with a permisive license.
  Methods: Building on top of strong base models like Llama 3.1 and Qwen 2.5,
Aloe Beta uses a custom dataset to enhance public data with synthetic Chain of
Thought examples. The models undergo alignment with Direct Preference
Optimization, emphasizing ethical and policy-aligned performance in the
presence ofjailbreaking attacks. Evaluation includes close-ended, open-ended,
safety andhuman assessments, to maximize the reliability of results.
  Results: Recommendations are made across the entire pipeline, backed by the
solid performance of the Aloe Family. These models deliver competitive
performance across healthcare benchmarks and medical fields, and are often
preferred by healthcare professionals. On bias and toxicity, the Aloe Beta
models significantly improve safety, showing resilience to unseen jailbreaking
attacks. For a responsible release, a detailed risk assessment specific to
healthcare is attached to the Aloe Family models.
  Conclusion: The Aloe Beta models, and the recipe that leads to them, are a
significant contribution to the open-source medical LLM field, offering
top-of-the-line performance while maintaining high ethical requirements. This
work sets a new standard for developing and reporting alignedLLMsin
healthcare.View arXiv pageView PDFAdd to collectionCommunitydariogPaper submitterabout 18 hours agoUpdated version of the Aloe family of healthcare LLMs, including full details on the entire data and training pipelines. Includes 4 different evaluations, and a risk assessment for LLMs specialized on medical topics.See translationReplyEditPreviewUpload images, audio, and videos by dragging in the text input, pasting, orclicking here.Tap or paste here to upload imagesComment·Sign uporlog into comment